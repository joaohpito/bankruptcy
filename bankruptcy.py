# -*- coding: utf-8 -*-
"""CA2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vThOZAUavoglb2vHoXCzYzF7y-BBtKeP

# Import libraries and dataset
"""

# Import the necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import tree
from sklearn.model_selection import GridSearchCV
from sklearn import metrics
from imblearn.over_sampling import SMOTE  # imblearn library can be installed using pip install imblearn
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier

# Importing dataset and examining it
df = pd.read_csv("company_bankruptcy.xlsx")
pd.set_option('display.max_columns', None) # Will ensure that all columns are displayed
df.head()

df.shape

# Inspecting the data
df.info()

"""# Data manipulation and modelling"""

# Divide the dataset into label(target) and features
X = df.drop(columns='Bankrupt')
y = df['Bankrupt']

X.head()

y.head()

# check the shape again
df.shape

df.describe()

# Plot the target variable to see their distribution and check if there is class imbalance
import matplotlib.pyplot as plt
df.Bankrupt.value_counts().plot.barh()
plt.xlabel('Number of samples')
_ = plt.title('Number of samples per classes present\n in the target')

# Normalizing numerical features so that each feature has mean 0 and variance 1
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into train and test dataset
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=7)

print(X_train.shape)
print(X_test.shape)

"""# Random Forest"""

#n estimators as 100
#minimum sample size 20
from sklearn.ensemble import RandomForestClassifier
rfm = RandomForestClassifier()
rfm.fit(X_train, y_train)
y_pred_rf = rfm.predict(X_test)
rfm

rfm = RandomForestClassifier() #baseline model
rfm.fit(X_train,y_train)

# Predicting using the Random Forest model
rfm_pred = rfm.predict(X_test)

"""### Model Evaluation """

#classification report
from sklearn.metrics import classification_report, accuracy_score
print(classification_report(y_test, rfm_pred))

"""### Displaying important features"""

# importance features
featimp_rfm = pd.Series(rfm.feature_importances_, index=list(X)).sort_values(ascending=False)
print(featimp_rfm)

# Plot feature importances
featimp_plot_rfm = pd.Series(rfm.feature_importances_, X.columns)
n = 10
plt.figure(figsize=(10,n/2))
plt.title(f'Top {n} features')
featimp_plot_rfm.sort_values()[-n:].plot.barh(color='grey');

"""### Hyperparameter tuning"""

# parameters={"n_estimators": [20,50,100,200,500],
#           	"min_samples_split": [10,20,30,40,50],
#             "criterion":["entropy","gini"],
#             "random_state":[2,5,10,20]}

# # calculating different regression metrics
# from sklearn.model_selection import GridSearchCV
# tuning_model=GridSearchCV(rfm,param_grid=parameters,scoring='recall',cv=5) # with cross-validation = 5

# tuning_model.fit(X_train, y_train)

# best_parameters = tuning_model.best_params_
# print(best_parameters)

# best_result = tuning_model.best_score_ # Mean cross-validated score of the best_estimator
# print(best_result)

"""###Displaying important features"""

# Building Random Forest using the tuned parameters
rfm = RandomForestClassifier(criterion='gini',min_samples_split=10,n_estimators=20,random_state=2)
rfm.fit(X_train,y_train)
y_pred_rf = rfm.predict(X_test)
rfm

# Predicting using the Random Forest model
rfm_pred = rfm.predict(X_test)

#classification report
from sklearn.metrics import classification_report, accuracy_score
print(classification_report(y_test, rfm_pred))

"""#Decision Tree model"""

# Decision Tree
from sklearn.tree import DecisionTreeClassifier
DTm = DecisionTreeClassifier(max_depth=5, random_state=2)
DTm.fit(X_train, y_train)
DTM_pred = DTm.predict(X_test)
DTm

"""### Model Evaluation"""

#classification report
from sklearn.metrics import classification_report, accuracy_score
print(classification_report(y_test, DTM_pred))

"""### Displaying important features"""

# Plot feature importances
featimp_plot = pd.Series(DTm.feature_importances_, X.columns)
n = 10
plt.figure(figsize=(10,n/2))
plt.title(f'Top {n} features')
featimp_plot.sort_values()[-n:].plot.barh(color='grey');

"""### Displaying the Tree"""

# Display the tree
import graphviz
from sklearn.tree import export_graphviz

dot_data = export_graphviz(DTm, 
                           out_file=None, 
                           max_depth=5, 
                           feature_names=X.columns, 
                          #  class_names=DTm.score, 
                           impurity=False, 
                           filled=True, 
                           #proportion=True, 
                           #rotate=True, 
                           rounded=True)

graphviz.Source(dot_data)



"""### Hyperparameter tuning"""

# parameters={"max_depth": [3,5,10],
#           	"max_leaf_nodes": [10,30,50,100,200],
#           	"min_samples_leaf": [1,2,3],
#           	"min_samples_split": [1,2,3],
#           	"min_weight_fraction_leaf": [0.1,0.2,0.3],
#           	"splitter": ["best,"random"],
#             "ccp_alpha": [0.0,0.1,0.2],
#             "criterion": ["squared_error", "friedman_mse", "absolute_error", "poisson"],
#             "max_features":[None,1,2], 
#             "random_state":[None,1,2], 
#             "min_impurity_decrease": [0.0,0.1,0.2]}

## Hyper parameters have been run in two batches with the following outputs ## 
# { 'max_depth': 10,
# 	'max_leaf_nodes': 30,
# 	'min_samples_leaf': 3,
# 	'min_samples_split': 2,
# 	'min_weight_fraction_leaf': 0.1,
# 	'splitter': 'random'}

# {'ccp_alpha': 0.0,
#  'criterion': 'absolute_error',
#  'max_features': None,
#  'min_impurity_decrease': 0.0,
#  'random_state': 1}

# # calculating different regression metrics
# from sklearn.model_selection import GridSearchCV
# tuning_model=GridSearchCV(DTm,param_grid=parameters,scoring='recall',cv=5) # with cross-validation = 5

# tuned model with best hyperparameters (not all of them are here, because the code wasn't running)
tm_tuned= DecisionTreeClassifier(max_depth= 10,max_leaf_nodes= 30,min_samples_leaf= 3)
# fit with the scaled variable
tm_tuned.fit(X_train, y_train)

# Predicting using the tuned Decision Tree model
tm_pred_tuned = tm_tuned.predict(X_test)

#classification report 
from sklearn.metrics import classification_report, accuracy_score
print(classification_report(y_test, tm_pred_tuned))

"""# Gradient Boost """

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error as mse

gbm = GradientBoostingClassifier(random_state=1,max_depth=2, n_estimators=3, learning_rate=1.0)  
gbm.fit(X_train,y_train)

# Predicting using the Gradient Boosting Model
gbm_pred = gbm.predict(X_test)

"""### Model evaluation"""

#classification report
from sklearn.metrics import classification_report, accuracy_score
print(classification_report(y_test, gbm_pred))

"""### Displaying important features"""

## Displaying important features
# importance features
featimp_gbm = pd.Series(gbm.feature_importances_, index=list(X)).sort_values(ascending=False)
print(featimp_gbm)

# Plot feature importances
featimp_plot_gbm = pd.Series(gbm.feature_importances_, X.columns)
n = 10
plt.figure(figsize=(10,n/2))
plt.title(f'Top {n} features')
featimp_plot_gbm.sort_values()[-n:].plot.barh(color='grey');

"""### Hyperparameter tuning"""

# # Tuning the Gradent Boost parameters 'n_estimators','max_depth','max_leaf_nodes','learning_rate' and implementing cross-validation using Grid Search
# gbc = GradientBoostingClassifier(random_state=1)
# grid_param = {'n_estimators': [10,20,30,40,50], 'max_depth' : [10,20,30,50,100], 'max_leaf_nodes': [5,10,20,50,150], 'learning_rate': [0.2,0.4,0.8,1.0]}

# gd_sr = GridSearchCV(estimator=gbc, param_grid=grid_param, scoring='recall', cv=5)

# gd_sr.fit(X_train, y_train)

# best_parameters = gd_sr.best_params_
# print(best_parameters)

# best_result = gd_sr.best_score_ # Mean cross-validated score of the best_estimator
# print(best_result)

"""### Displaying important features"""

# Building Gradient Boost using the tuned parameters and getting classification report
gbc = GradientBoostingClassifier(learning_rate=0.4,n_estimators=30, max_depth=20, max_leaf_nodes=10)
gbc.fit(X_train,y_train)
featimp = pd.Series(gbc.feature_importances_, index=list(X)).sort_values(ascending=False)
print(featimp)

y_pred_gbc = gbc.predict(X_test)
print('Classification report: \n', metrics.classification_report(y_test, y_pred_gbc))

# Plot feature importances
featimp_plot_gbc_tuned = pd.Series(gbc.feature_importances_, X.columns)
n = 10
plt.figure(figsize=(10,n/2))
plt.title(f'Top {n} features')
featimp_plot_gbc_tuned.sort_values()[-n:].plot.barh(color='grey');

"""### Displaying the Tree"""

# Display the tree
import graphviz
from sklearn.tree import export_graphviz

dot_data = export_graphviz(gbm, 
                           out_file=None, 
                           max_depth=5, 
                           feature_names=X.columns, 
                          #  class_names=DTm.score, 
                           impurity=False, 
                           filled=True, 
                           #proportion=True, 
                           #rotate=True, 
                           rounded=True)

graphviz.Source(dot_data)